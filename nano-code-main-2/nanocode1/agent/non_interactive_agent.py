import asyncio
import json
import os
import time
from typing import List, Dict, Any
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown as M

from ..core.session import Session
from ..llm import llm_complete
from ..agent_tool.tools import OS_TOOLS, UTIL_TOOLS, PYTHON_TOOLS, GIT_TOOLS
from ..utils.logger import AIConsoleLogger
from ..prompts import (
    SYSTEM_PROMPT, RAW_ANALYSIS_PROMPT, Code_analysis_prompt, Data_anlaysis_prompt, 
    File_analysis_prompt, Graph_analysis_prompt
)
from ..models.dissertation_plan import DissertationPlan
from ..models.output_format import ReportModel, ImageArtifact, TableArtifact, CodeArtifact, FileArtifact

# äº§å‡ºartifactä¼šç”¨åˆ°çš„å·¥å…·ï¼ˆæ¨¡å—çº§å¸¸é‡ï¼Œé¿å…é‡å¤å®šä¹‰ï¼‰
ARTIFACT_TOOLS = ["create_file", "write_file", "RunCommand", "render_mermaid"]

# ç®€åŒ–çš„ä»»åŠ¡ç»“æœç®¡ç†å™¨
class TaskResultManager:
    @staticmethod
    def create_fully_completed_result(phase_name: str, output_path: str, agent_output, iteration: int) -> Dict[str, Any]:
        return {
            "status": "completed",
            "phase": phase_name,
            "output_path": output_path,
            "iteration": iteration,
            "message": f"ä»»åŠ¡å®Œæˆ: {phase_name}",
            "agent_output": agent_output
        }

# æ§åˆ¶å°è¾“å‡ºæ•è·å™¨
class ConsoleOutputCapture:
    def __init__(self, console: Console):
        self.console = console
        self.captured_output = []
    
    def capture_print(self, content: str):
        self.captured_output.append(content)
        self.console.print(content)


class NonInteractiveAgent:
    
    def __init__(self, session: Session, console: Console = None):
        self.session = session
        self.console = console or Console()
        self.all_tools = OS_TOOLS.merge(UTIL_TOOLS).merge(PYTHON_TOOLS).merge(GIT_TOOLS)
        self.execution_log = []
        
        # ä½¿ç”¨ä¸“é—¨çš„ç®¡ç†å™¨
        self.console_capture = ConsoleOutputCapture(self.console)
        
        # TODOåˆ—è¡¨ç®¡ç†
        self.session.todo_list = []
        
        # æ–‡ä»¶æ‰«æçŠ¶æ€ç®¡ç†
        self._recent_files_scanned = False
    
    
    async def execute_task(self, dissertation_plan: DissertationPlan) -> Dict[str, Any]: 
        """
        æ‰§è¡Œä»»åŠ¡çš„ä¸»æµç¨‹

        Args:
            dissertation_plan (DissertationPlan): ä»»åŠ¡è®¡åˆ’

        Returns:
            Dict[str, Any]: ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        task_prompt = self._convert_dissertation_plan_to_prompt(dissertation_plan)
        
        # ç¬¬ä¸€é˜¶æ®µï¼šæ‰§è¡Œå½“å‰ä»»åŠ¡ï¼ˆä¸ç®¡æ˜¯å¦éœ€è¦æœç´¢ï¼‰
        messages = [{"role": "user", "content": task_prompt}]
        
        # æ ¹æ® is_first_time é€‰æ‹©ä½¿ç”¨çš„system prompt
        if dissertation_plan.is_first_time:
            selected_prompt = RAW_ANALYSIS_PROMPT
            phase_name = "first_time_analysis"
        else:
            selected_prompt = SYSTEM_PROMPT
            phase_name = "task_execution"
        
        
        self.console.print(f"ğŸš€ å¼€å§‹æ‰§è¡Œé˜¶æ®µ: {phase_name}")
        
        # æ‰§è¡Œå½“å‰é˜¶æ®µçš„ä»»åŠ¡
        result = await self._autonomous_execution_loop(
            messages,
            system_prompt=selected_prompt
        )
        
        # æ„å»ºå½“å‰é˜¶æ®µçš„è¾“å‡º
        agent_output = await self._build_agent_output(
            result.get("final_message", ""),
            result.get("execution_log", []),
            is_first_time=dissertation_plan.is_first_time
        )
        
        # ç»Ÿä¸€è¾“å‡ºæ–‡ä»¶å
        output_filename = "agent_output.json"
        output_path = f"{self.session.working_dir}/{output_filename}"
        agent_output.save_json(output_path)
        
        self.console.print(f"âœ… {phase_name} é˜¶æ®µå®Œæˆ")
        
        # ç›´æ¥è¿”å›ä»»åŠ¡å®Œæˆç»“æœï¼ˆæœç´¢åˆ¤æ–­é€»è¾‘å·²ç§»é™¤ï¼‰
        return TaskResultManager.create_fully_completed_result(
            phase_name, output_path, agent_output, result.get("iteration", 0)
        )
  
    def _convert_dissertation_plan_to_prompt(self, plan: DissertationPlan) -> str: 
        """
        æŠŠjsonä¸­çš„ä»»åŠ¡è¦æ±‚è½¬æ¢ä¸ºllmçš„è¾“å…¥ï¼›è‹¥å­˜åœ¨å¤–éƒ¨æœç´¢èµ„æ–™ï¼ˆagent_communicate.responseï¼‰ï¼Œä¼šæ³¨å…¥åˆ°æç¤ºä¸­ã€‚

        Args:
            plan (DissertationPlan): ä»»åŠ¡è®¡åˆ’

        Returns:
            str: llmçš„è¾“å…¥
        """
        prompt_parts = []
        
        # ä»£ç ä»“åº“åˆ†æéƒ¨åˆ†
        if plan.experimental_requirements.code_repository_review:
            repo = plan.experimental_requirements.code_repository_review
            prompt_parts.extend([
                "### ä»£ç ä»“åº“åˆ†æ",
                f"- ä»“åº“åœ°å€ï¼š{repo.url}",
                f"- æè¿°ï¼š{repo.description}",
                f"- åˆ†æé‡ç‚¹ï¼š{', '.join(repo.analysis_focus)}",
                ""
            ])
        
        # å®éªŒä»»åŠ¡éƒ¨åˆ†
        if plan.experimental_requirements.reproduction_tasks:
            prompt_parts.append("### éœ€è¦å®Œæˆçš„å®éªŒä»»åŠ¡")
            for i, task in enumerate(plan.experimental_requirements.reproduction_tasks, 1):
                prompt_parts.extend([
                    f"{i}. **{task.phase}**",
                    f"   - ç›®æ ‡ï¼š{task.target}",
                    f"   - æ–¹æ³•ï¼š{task.methodology}",
                    ""
                ])
        
        # è¯„ä¼°è¦æ±‚
        if plan.experimental_requirements.critical_evaluation:
            eval_req = plan.experimental_requirements.critical_evaluation
            prompt_parts.extend([
                "### æ‰¹åˆ¤æ€§è¯„ä¼°è¦æ±‚",
                f"- å¤±è´¥æ¡ˆä¾‹ç ”ç©¶ï¼š{eval_req.failure_case_study}",
                f"- æ”¹è¿›æ–¹å‘ï¼š{', '.join(eval_req.improvement_directions)}",
                ""
            ])
        
        # ç›¸å…³èµ„æº
        if plan.urls:
            prompt_parts.append("### ç›¸å…³èµ„æº")
            for url_info in plan.urls:
                prompt_parts.append(f"- {url_info.url}: {url_info.description}")
            prompt_parts.append("")

        # å¤–éƒ¨æœç´¢èµ„æ–™è¡¥å……ï¼ˆä»…å½“å­˜åœ¨éç©º response æ—¶æ³¨å…¥ï¼‰
        try:
            comms = getattr(plan, "agent_communicate", None)
            if comms:
                enriched_lines: List[str] = []
                count = 0
                for comm in comms:
                    resp = getattr(comm, "response", None)
                    if resp and isinstance(resp, str) and resp.strip():
                        count += 1
                        # æ§åˆ¶é•¿åº¦ï¼Œé¿å…æç¤ºè¿‡é•¿
                        resp_snippet = resp.strip()
                        if len(resp_snippet) > 3000:
                            resp_snippet = resp_snippet[:3000] + "â€¦"
                        req_snippet = getattr(comm, "request", "")
                        if req_snippet and len(req_snippet) > 3000:
                            req_snippet = req_snippet[:3000] + "â€¦"
                        enriched_lines.append(f"- èµ„æ–™ {count}ï¼ˆå¯¹åº”éœ€æ±‚ï¼š{req_snippet}ï¼‰\n  {resp_snippet}")
                        if count >= 5:
                            break
                if enriched_lines:
                    prompt_parts.append("### å¤–éƒ¨æœç´¢èµ„æ–™è¡¥å……ï¼ˆç”¨äºæé«˜å®Œæˆè´¨é‡ä¸å‡†ç¡®æ€§ï¼‰")
                    prompt_parts.extend(enriched_lines)
                    prompt_parts.append("")
        except Exception:
            pass
        
        return "\n".join(prompt_parts)
    
    async def _build_agent_output(self, report: str, execution_log: List[dict], is_first_time: bool = False) -> ReportModel: 
        """
        æŒ‰ç…§è§„å®šæ ¼å¼è¾“å‡ºï¼Œæ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„é™„ä»¶ç±»å‹
        
        å½“ is_first_time=True æ—¶ï¼Œå°†ç”Ÿæˆçš„ markdown å†…å®¹ä¿å­˜åœ¨ report å­—æ®µä¸­ï¼Œ
        ä¸å°† .md æ–‡ä»¶ä½œä¸º artifact è¿”å›ã€‚

        Args:
            report (str): æŠ¥å‘Šå†…å®¹
            execution_log (List[dict]): æ‰§è¡Œæ—¥å¿—
            is_first_time (bool): æ˜¯å¦ä¸ºç¬¬ä¸€æ¬¡åˆ†æ

        Returns:
            ReportModel: è¾“å‡ºç»“æœ
        """
        artifacts = []
        processed_files = set()  # ç”¨äºå»é‡çš„æ–‡ä»¶é›†åˆ
        
        # æ”¶é›†æ‰§è¡Œè¿‡ç¨‹ä¸­æ–°åˆ›å»ºçš„æ–‡ä»¶ä½œä¸ºé™„ä»¶
        for log_entry in execution_log:
            tool_name = log_entry.get("tool", "")

            if tool_name in ARTIFACT_TOOLS:
                new_file_artifacts = await self._detect_new_files(log_entry)
                
                # å»é‡å¤„ç†ï¼šåªæ·»åŠ æœªå¤„ç†è¿‡çš„æ–‡ä»¶
                for artifact in new_file_artifacts:
                    file_identifier = self._get_artifact_file_identifier(artifact)
                    if file_identifier not in processed_files:
                        processed_files.add(file_identifier)
                        
                        # ç¬¬ä¸€æ¬¡åˆ†ææ—¶ï¼Œè·³è¿‡ .md æ–‡ä»¶ä½œä¸º artifact
                        # å› ä¸º markdown å†…å®¹å·²ç»åœ¨ report å­—æ®µä¸­
                        if is_first_time and hasattr(artifact, 'title') and artifact.title.endswith('.md'):
                            continue
                            
                        artifacts.append(artifact)
        
        return ReportModel(
            report=report,
            artifacts=artifacts
        )
    
    def _get_artifact_file_identifier(self, artifact) -> str:
        """è·å–artifactçš„å”¯ä¸€æ ‡è¯†ç¬¦ç”¨äºå»é‡"""
        return getattr(artifact, 'title', '')
    
    async def _detect_new_files(self, log_entry: dict) -> list:
        """æ£€æµ‹å·¥å…·æ‰§è¡Œåæ–°åˆ›å»ºçš„æ–‡ä»¶å¹¶åˆ›å»ºå¯¹åº”artifacts"""
        artifacts = []
        
        # ä»æ—¥å¿—ä¸­è·å–æ‰§è¡Œå‰åçš„æ–‡ä»¶æ—¶é—´æˆ³ä¿¡æ¯
        file_changes = log_entry.get("file_changes", {})
        new_files = file_changes.get("created", [])
        
        # å¦‚æœæ²¡æœ‰æ–‡ä»¶å˜åŒ–ä¿¡æ¯ï¼Œå›é€€åˆ°æ‰«æå·¥ä½œç›®å½•ï¼ˆä½†åªæ‰«æä¸€æ¬¡ï¼‰
        if not new_files:
            if not hasattr(self, '_recent_files_scanned') or not self._recent_files_scanned:
                new_files = self._scan_recent_files()
                self._recent_files_scanned = True
            else:
                new_files = []
        
        for file_path in new_files:
            if not Path(file_path).exists():
                continue
                
            # è·å–æˆ–ç”ŸæˆLLMåˆ†æç»“æœ
            analysis = log_entry.get("llm_analysis", "")
            
            # å¦‚æœæ²¡æœ‰ç°æœ‰åˆ†æï¼Œä¸ºéœ€è¦åˆ†æçš„æ–‡ä»¶ç±»å‹ç”Ÿæˆåˆ†æ
            if not analysis:
                file_extension = Path(file_path).suffix.lower()
                if file_extension in ['.png', '.csv', '.py']:
                    try:
                        # è¯»å–æ–‡ä»¶å†…å®¹ç”¨äºåˆ†æ
                        content = ""
                        if file_extension == '.py':
                            with open(file_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                        analysis = await self._analyze_generated_content(file_path, content)
                    except Exception as e:
                        analysis = f"æ— æ³•åˆ†ææ–‡ä»¶: {str(e)}"
            
            artifact = self._create_artifact_by_extension(file_path, analysis)
            if artifact:
                artifacts.append(artifact)
        
        return artifacts
    
    def _scan_recent_files(self) -> list[str]:
        """æ‰«æå·¥ä½œç›®å½•ä¸­æœ€è¿‘åˆ›å»ºçš„æœ‰æ„ä¹‰æ–‡ä»¶"""
        current_time = time.time()
        recent_files = set()  # å»é‡
        
        # åªå…³æ³¨æ ¸å¿ƒæ–‡ä»¶æ ¼å¼
        target_extensions = {'.csv', '.py', '.png', '.md', '.mmd'}
        
        try:
            for root, dirs, files in os.walk(self.session.working_dir):
                # è·³è¿‡ç¼“å­˜ç›®å½•
                dirs[:] = [d for d in dirs if not d.startswith(('__pycache__', '.pytest_cache', '.git', '.cache'))]
                
                for file in files:
                    # åªå¤„ç†ç›®æ ‡æ‰©å±•åçš„æ–‡ä»¶
                    if not any(file.lower().endswith(ext) for ext in target_extensions):
                        continue
                        
                    file_path = os.path.join(root, file)
                    
                    if not self.session.ignore_path(file_path):
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æœ€è¿‘5åˆ†é’Ÿå†…åˆ›å»º
                        if current_time - os.path.getctime(file_path) < 300:
                            recent_files.add(file_path)
        except Exception:
            pass
            
        return list(recent_files)
    
    def _create_artifact_by_extension(self, file_path: str, analysis: str = ""):
        """æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ›å»ºå¯¹åº”çš„artifact"""
        try:
            file_extension = Path(file_path).suffix.lower()
            file_name = Path(file_path).name
            
            if file_extension == '.png':
                # åˆ›å»ºä¸´æ—¶å®ä¾‹æ¥è°ƒç”¨image_to_base64æ–¹æ³•
                return ImageArtifact(
                    image=file_path,
                    title=file_name,
                    description=analysis  # å®Œå…¨ä¾èµ–LLMåˆ†æ
                )
            
            elif file_extension == '.csv':
                return TableArtifact(
                    table=file_path,
                    title=file_name,
                    description=analysis  # å®Œå…¨ä¾èµ–LLMåˆ†æ
                )
            
            elif file_extension == '.py':
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    return CodeArtifact(
                        code=content,
                        title=file_name,
                        description=analysis  # å®Œå…¨ä¾èµ–LLMåˆ†æ
                    )
                except Exception:
                    pass
            
            elif file_extension in ['.md', '.mmd']:
                # ä¸ºMarkdownæ–‡ä»¶æä¾›åŸºæœ¬æè¿°
                if not analysis:
                    analysis = f"Markdownæ–‡æ¡£: {file_name}"
                return FileArtifact(
                    file=file_path,
                    title=file_name,
                    description=analysis
                )
                
        except Exception:
            return None
    
    def _get_formatted_memories(self) -> str:
        code_memories = self.session.get_memory()
        if code_memories:
            return f"Below are some working memories:\n{code_memories}"
        else:
            return ""
    
    def _get_formatted_system_prompt(self) -> str:
        return SYSTEM_PROMPT.format(
            working_dir=self.session.working_dir,
            todo_status=self._get_todo_status(),
            memories=self._get_formatted_memories()
        )
    
    def _get_todo_status(self) -> str:
        """è·å–TODOçŠ¶æ€æ–‡æœ¬"""
        if not hasattr(self.session, 'todo_list') or not self.session.todo_list:
            return "TODO Status: No TODO list created yet. Create one at the start!"
        
        total = len(self.session.todo_list)
        completed = sum(1 for item in self.session.todo_list if item.status == "completed")
        completion_rate = (completed / total) * 100 if total > 0 else 0
        
        status_lines = [f"TODO Progress: {completed}/{total} completed ({completion_rate:.0f}%)"]
        
        for item in self.session.todo_list:
            status_icon = "âœ…" if item.status == "completed" else "ğŸ”„" if item.status == "in_progress" else "â³"
            status_lines.append(f"{status_icon} [{item.id}] {item.description}")
        
        return "\n".join(status_lines)
    
    def _is_todo_complete(self) -> bool:
        """æ£€æŸ¥TODOæ˜¯å¦å…¨éƒ¨å®Œæˆ"""
        if not hasattr(self.session, 'todo_list') or not self.session.todo_list:
            return True  # æ²¡æœ‰TODOåˆ—è¡¨è§†ä¸ºå®Œæˆ
        
        return all(item.status == "completed" for item in self.session.todo_list)
    
    def _get_incomplete_todos(self) -> str:
        """è·å–æœªå®ŒæˆTODOé¡¹ç›®çš„æè¿°"""
        if not hasattr(self.session, 'todo_list') or not self.session.todo_list:
            return "No TODO items"
        
        incomplete = [item for item in self.session.todo_list if item.status != "completed"]
        if not incomplete:
            return "All TODO items completed"
        
        lines = []
        for item in incomplete:
            status_icon = "ğŸ”„" if item.status == "in_progress" else "â³"
            lines.append(f"{status_icon} [{item.id}] {item.description}")
        
        return "\n".join(lines)


    async def _analyze_generated_content(self, file_path: str, content: str) -> str: 
        """
        åˆ†æç”Ÿæˆçš„å†…å®¹ï¼Œæ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©ä¸åŒpromptï¼Œoutput formatä¸­çš„description

        Args:
            file_path (str): æ–‡ä»¶è·¯å¾„
            content (str): æ–‡ä»¶å†…å®¹

        Returns:
            content: åˆ†æç»“æœ
        """
        file_extension = Path(file_path).suffix.lower()
        file_name = Path(file_path).name
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹å®šåˆ¶åˆ†ææç¤º
        if file_extension in ['.png']:
            analysis_prompt = Graph_analysis_prompt.format(file_name = file_name, file_path = file_path)

        elif file_extension in ['.csv', ]:
            analysis_prompt = Data_anlaysis_prompt.format(file_name = file_name, file_path = file_path)
        elif file_extension in ['.py']:
            analysis_prompt = Code_analysis_prompt.format(file_name = file_name, content = content)
        else:
            analysis_prompt = File_analysis_prompt.format(file_name = file_name, content = content)     
        try:
            analysis_response = await llm_complete(
                self.session,
                self.session.working_env.llm_main_model,
                [{"role": "user", "content": analysis_prompt}],
                system_prompt=self._get_formatted_system_prompt()
            )
            return analysis_response.choices[0].message.content
        except Exception as e:
            return f"åˆ†æç”Ÿæˆæ—¶å‡ºé”™: {str(e)}"
    
    
    async def _autonomous_execution_loop(
        self, 
        messages: List[dict], 
        system_prompt: str
        ) -> Dict[str, Any]:
        """
        è‡ªåŠ¨æ‰§è¡Œå¾ªç¯ã€‚

        Args:
            messages (List[dict]): æ¶ˆæ¯å†å²
            system_prompt (str): 

        Returns:
            Dict[str, Any]: ä»»åŠ¡æ‰§è¡Œç»“æœï¼ŒåŒ…å«çŠ¶æ€ã€æœ€ç»ˆæ¶ˆæ¯ã€è¿­ä»£æ¬¡æ•°å’Œæ‰§è¡Œæ—¥å¿—ã€‚
        """
        iteration = 0
        
        # è·å–é¡¹ç›®å†…å­˜
        memories = self._get_formatted_memories()

        
        while True:
            iteration += 1
            self.console.print(f"ğŸ”„ æ‰§è¡Œè½®æ¬¡ {iteration}")
            
            # è°ƒç”¨LLM
            response = await llm_complete(
                self.session,
                self.session.working_env.llm_main_model,
                messages,
                system_prompt=system_prompt.format(
                    working_dir=self.session.working_dir,
                    todo_status=self._get_todo_status(),
                    memories=memories
                ),
                tools=self.all_tools.get_schemas(),
            )
            
            choice = response.choices[0]
            
            if choice.finish_reason != "tool_calls":
                # æ£€æŸ¥TODOå®ŒæˆçŠ¶æ€
                todo_complete = self._is_todo_complete()
                
                if todo_complete:
                    return {
                        "status": "completed",
                        "final_message": choice.message.content,
                        "iteration": iteration,
                        "execution_log": self.execution_log
                    }
                else:
                    # TODOæœªå®Œæˆï¼Œç»§ç»­æ‰§è¡Œ
                    incomplete_items = self._get_incomplete_todos()
                    
                    # å‘æ¶ˆæ¯å†å²æ·»åŠ æé†’
                    reminder = f"""Your TODO list is not yet complete. You cannot finish until all items are completed.

Incomplete items:
{incomplete_items}

Please continue using tools to complete these remaining tasks. Use update_todo_status to mark items as completed when done."""
                    
                    messages.append({"role": "assistant", "content": choice.message.content})
                    messages.append({"role": "user", "content": reminder})
                    continue
            
            # æ–°å¢ï¼šå³ä½¿åœ¨è°ƒç”¨å·¥å…·ï¼Œä¹Ÿæ£€æŸ¥TODOçŠ¶æ€
            elif iteration > 60 and self._is_todo_complete():
                self.console.print("âœ… TODOå®Œæˆï¼Œå¼ºåˆ¶ç»“æŸä»»åŠ¡ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰")
                # ä¸ç›´æ¥returnï¼Œè€Œæ˜¯è®¾ç½®å®ŒæˆçŠ¶æ€è®©å¾ªç¯æ­£å¸¸é€€å‡º
                # è¿™æ ·å¯ä»¥ç¡®ä¿execute_taskä¸­çš„ReportModelæ„å»ºä»£ç èƒ½å¤Ÿæ‰§è¡Œ
                # ä½¿ç”¨LLMçš„æœ€åè¾“å‡ºä½œä¸ºæœ€ç»ˆæŠ¥å‘Šå†…å®¹
                final_message = choice.message.content if choice.message.content else "ä»»åŠ¡å·²å®Œæˆï¼Œæ‰€æœ‰TODOé¡¹ç›®å·²å®Œæˆ"
                break
            
            # æ˜¾ç¤ºAIçš„æ€è€ƒè¿‡ç¨‹
            if choice.message.content:
                # è½¬ä¹‰Rich Consoleæ ‡è®°ä»¥é¿å…è§£æé”™è¯¯
                safe_content = choice.message.content.replace('[', '\\[').replace(']', '\\]')
                self.console.print(Panel(M(safe_content), title="Assistant"))
            
            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
            messages.append(choice.message.model_dump())

            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            tool_calls = [
                t for t in choice.message.tool_calls
                if self.all_tools.has_tool(t.function.name)
            ]
            
            # å·¥å…·è°ƒç”¨ä¿¡æ¯
            for t in tool_calls:
                self.console.print(f"ğŸ”§ [bold blue]è°ƒç”¨å·¥å…·:[/bold blue] {t.function.name}")
                try:
                    args = json.loads(t.function.arguments)
                    self.console.print(f"ğŸ“ [bold green]å‚æ•°:[/bold green] {json.dumps(args, indent=2, ensure_ascii=False)}")
                except json.JSONDecodeError:
                    self.console.print(f"ğŸ“ [bold yellow]å‚æ•° (åŸå§‹):[/bold yellow] {t.function.arguments}")
                self.console.print("â”€" * 50)
            
            # æ‰¹é‡æ‰§è¡Œå·¥å…·
            tasks = [
                self.all_tools.execute(
                    self.session, t.function.name, json.loads(t.function.arguments)
                )
                for t in tool_calls
            ]
            
            results = await asyncio.gather(*tasks)
            
            # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²å¹¶åˆ†æç”Ÿæˆçš„å†…å®¹
            for t, r in zip(tool_calls, results):
                messages.append({
                    "role": "tool",
                    "tool_call_id": t.id,
                    "content": r.for_llm,
                })
                
                # åˆ›å»ºåŸºç¡€æ‰§è¡Œæ—¥å¿—
                log_entry = {
                    "iteration": iteration,
                    "tool": t.function.name,
                    "args": json.loads(t.function.arguments),
                    "result": r.for_human
                }
                
                # å¦‚æœæ˜¯artifactåˆ›å»ºå·¥å…·ï¼Œè¯·æ±‚LLMå¯¹ç”Ÿæˆå†…å®¹è¿›è¡Œåˆ†æ
                if any(tool.lower() in t.function.name.lower() for tool in ARTIFACT_TOOLS):
                    args = log_entry.get("args", {})
                    file_path = args.get("file_path", "")
                    content = args.get("content", "")
                    
                    if file_path and content:
                        file_extension = Path(file_path).suffix.lower()
                        # åªä¸ºéœ€è¦æ·±åº¦åˆ†æçš„æ–‡ä»¶ç±»å‹ç”ŸæˆLLMåˆ†æ
                        if file_extension in ['.py', '.csv']:
                            analysis = await self._analyze_generated_content(file_path, content)
                            log_entry["llm_analysis"] = analysis
                        elif file_extension == '.png':
                            # PNGæ–‡ä»¶ä½¿ç”¨æ–‡ä»¶è·¯å¾„è¿›è¡Œåˆ†æï¼ˆä¸éœ€è¦contentï¼‰
                            analysis = await self._analyze_generated_content(file_path, "")
                            log_entry["llm_analysis"] = analysis
                
                self.execution_log.append(log_entry)
        
        # å¾ªç¯ç»“æŸåï¼Œè¿”å›å®ŒæˆçŠ¶æ€ï¼ˆå¤„ç†breakæƒ…å†µï¼‰
        # ç¡®ä¿final_messageæ€»æ˜¯æœ‰åˆé€‚çš„å€¼
        if 'final_message' not in locals():
            final_message = "ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œæ‰€æœ‰TODOé¡¹ç›®å·²å®Œæˆ"
        
        return {
            "status": "completed",
            "final_message": final_message,
            "iteration": iteration,
            "execution_log": self.execution_log
        }


async def run_intelligent_task(dissertation_plan: DissertationPlan, working_dir: str = None): 
    """
    å¤–å±‚è°ƒç”¨

    Args:
        dissertation_plan (DissertationPlan): ä»»åŠ¡è®¡åˆ’ï¼ŒåŒ…å«ä»»åŠ¡æè¿°å’Œæ‰§è¡Œæ­¥éª¤ã€‚
        working_dir (str, optional): å·¥ä½œç›®å½•ï¼Œé»˜è®¤å½“å‰ç›®å½•ã€‚

    Returns:
        Dict[str, Any]: ä»»åŠ¡æ‰§è¡Œç»“æœï¼ŒåŒ…å«çŠ¶æ€ã€æœ€ç»ˆæ¶ˆæ¯ã€è¿­ä»£æ¬¡æ•°å’Œæ‰§è¡Œæ—¥å¿—ã€‚
    """
    console = Console()
    
    # è®¾ç½®å·¥ä½œç›®å½•
    if working_dir is None:
        working_dir = os.getcwd()
    
    # åˆ›å»ºä¼šè¯
    session = Session(working_dir=working_dir, logger=AIConsoleLogger(console))
    
    agent = NonInteractiveAgent(session, console)
    
    try:
        console.print("ğŸš€ Agentå¼€å§‹æ‰§è¡Œä»»åŠ¡...")
        
        result = await agent.execute_task(dissertation_plan)
        
        console.print(Panel(
            f"çŠ¶æ€: {result['status']}\n"
            f"æ‰§è¡Œé˜¶æ®µ: {result.get('phase', 'unknown')}\n"
            f"ä½¿ç”¨è½®æ¬¡: {result.get('iteration', 0)}\n"
            f"æ‰§è¡Œæ­¥éª¤: {len(agent.execution_log)} ä¸ª",
            title="ğŸ“Š ä»»åŠ¡æ‰§è¡Œæ‘˜è¦",
            border_style="green" if result['status'] == 'completed' else "yellow"
        ))
        
        return result
    finally:
        # ä¿å­˜æ£€æŸ¥ç‚¹
        session.save_checkpoints()
